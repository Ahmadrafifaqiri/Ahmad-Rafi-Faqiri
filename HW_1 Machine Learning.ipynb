{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMncSOL6rKDfUKQjtNAGSmX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmadrafifaqiri/Ahmadrafifaqiri/blob/main/HW_1%20Machine%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree [40 points + 10 bonus]"
      ],
      "metadata": {
        "id": "jxtXziMVK6wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "RxatJX18I8q-"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "    'x1': [0, 0, 0, 1, 0, 1, 0],\n",
        "    'x2': [0, 1, 0, 0, 1, 1, 1],\n",
        "    'x3': [1, 0, 1, 0, 1, 0, 0],\n",
        "    'x4': [0, 0, 1, 1, 0, 0, 1],\n",
        "    'y': [0, 0, 1, 1, 0, 0, 0]\n",
        "})"
      ],
      "metadata": {
        "id": "jJsw96CDI-Ds"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y):\n",
        "    probs = y.value_counts(normalize=True)\n",
        "    return -np.sum(probs * np.log2(probs))\n",
        "\n",
        "# Function to calculate information gain\n",
        "def information_gain(data, attribute):\n",
        "    # Calculate the entropy of the entire dataset\n",
        "    total_entropy = entropy(data['y'])\n",
        "\n",
        "    # Calculate the weighted entropy after splitting on the attribute\n",
        "    values = data[attribute].unique()\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in values:\n",
        "        subset = data[data[attribute] == value]\n",
        "        prob = len(subset) / len(data)\n",
        "        weighted_entropy += prob * entropy(subset['y'])\n",
        "\n",
        "    # Information gain is the reduction in entropy\n",
        "    return total_entropy - weighted_entropy"
      ],
      "metadata": {
        "id": "f2LPHvnFI-BH"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = ['x1', 'x2', 'x3', 'x4']\n",
        "for attr in attributes:\n",
        "    gain = information_gain(data, attr)\n",
        "    print(f'Information Gain for {attr}: {gain:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJqmHvbqI9-v",
        "outputId": "c856994f-a454-4bac-f0ad-a623c500dfb6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Information Gain for x1: 0.0617\n",
            "Information Gain for x2: 0.4696\n",
            "Information Gain for x3: 0.0060\n",
            "Information Gain for x4: 0.4696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
        "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Mild', 'Cool', 'Mild', 'Mild', 'Cool', 'Cool', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
        "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
        "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong', 'Weak', 'Weak'],\n",
        "    'Play': ['No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "def majority_error(df, column, target):\n",
        "    \"\"\"\n",
        "    Calculate the Majority Error (ME) for a given attribute.\n",
        "    \"\"\"\n",
        "    groups = df.groupby(column)[target].value_counts(normalize=True).unstack(fill_value=0)\n",
        "    me = 1 - groups.max(axis=1)\n",
        "    weighted_me = (df.groupby(column).size() / len(df)).dot(me)\n",
        "    return weighted_me\n",
        "\n",
        "def gini_index(df, column, target):\n",
        "    \"\"\"\n",
        "    Calculate the Gini Index (GI) for a given attribute.\n",
        "    \"\"\"\n",
        "    groups = df.groupby(column)[target].value_counts(normalize=True).unstack(fill_value=0)\n",
        "    gini = 1 - (groups**2).sum(axis=1)\n",
        "    weighted_gini = (df.groupby(column).size() / len(df)).dot(gini)\n",
        "    return weighted_gini"
      ],
      "metadata": {
        "id": "0Ycd2jg-I97u"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Majority Error for each attribute:\n",
        "attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
        "me_results = {attr: majority_error(df, attr, 'Play') for attr in attributes}"
      ],
      "metadata": {
        "id": "zBH_ORe4I95i"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Gini Index for each attribute:\n",
        "gini_results = {attr: gini_index(df, attr, 'Play') for attr in attributes}\n",
        "\n",
        "print(\"Majority Error for each attribute:\")\n",
        "for attr, me in me_results.items():\n",
        "    print(f\"{attr}: {me:.3f}\")\n",
        "\n",
        "print(\"\\nGini Index for each attribute:\")\n",
        "for attr, gi in gini_results.items():\n",
        "    print(f\"{attr}: {gi:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLDbWiYxI93D",
        "outputId": "629ca2b4-fe38-4d12-a503-b33abd256c4e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority Error for each attribute:\n",
            "Outlook: 0.286\n",
            "Temperature: 0.357\n",
            "Humidity: 0.286\n",
            "Wind: 0.357\n",
            "\n",
            "Gini Index for each attribute:\n",
            "Outlook: 0.343\n",
            "Temperature: 0.388\n",
            "Humidity: 0.367\n",
            "Wind: 0.405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the best attribute based on ME and GI:\n",
        "best_me_attr = min(me_results, key=me_results.get)\n",
        "best_gini_attr = min(gini_results, key=gini_results.get)\n",
        "\n",
        "print(f\"\\nBest attribute based on Majority Error: {best_me_attr}\")\n",
        "print(f\"Best attribute based on Gini Index: {best_gini_attr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xug8sfVCI90M",
        "outputId": "0e3c896d-b0a2-4f12-98cd-6bc77ccb3801"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best attribute based on Majority Error: Outlook\n",
            "Best attribute based on Gini Index: Outlook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split dataset based on an attribute:\n",
        "def split_dataset(df, column, value):\n",
        "    \"\"\"\n",
        "    Split the dataset based on a given attribute and value.\n",
        "    \"\"\"\n",
        "    return df[df[column] == value]"
      ],
      "metadata": {
        "id": "KjdF1eHJI9sT"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split dataset based on the best attribute from Majority Error\n",
        "For recursive splitting,repeat the process for each subset"
      ],
      "metadata": {
        "id": "krlStYksJlFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset = split_dataset(df, best_me_attr, df[best_me_attr].unique()[0])\n",
        "print(f\"\\nSubset based on {best_me_attr} = {df[best_me_attr].unique()[0]}:\")\n",
        "print(subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_399NPM6JXW4",
        "outputId": "de144e7e-4e73-4688-de42-fad0763c8bcf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Subset based on Outlook = Sunny:\n",
            "   Outlook Temperature Humidity    Wind Play\n",
            "0    Sunny         Hot     High    Weak   No\n",
            "1    Sunny         Hot     High  Strong   No\n",
            "7    Sunny        Mild     High    Weak   No\n",
            "8    Sunny        Cool   Normal  Strong  Yes\n",
            "10   Sunny        Mild   Normal    Weak  Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Tx0FOM3XJjD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from math import log2"
      ],
      "metadata": {
        "id": "ZH-VmsvUJXRX"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Outlook': ['Rain', 'Rain', 'Sunny', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Rain', 'Sunny', 'Rain', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Sunny'],\n",
        "    'Temperature': ['Hot', 'Hot', 'Mild', 'Hot', 'Hot', 'Mild', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Cool', 'Mild', 'Mild'],\n",
        "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'Normal', 'High', 'High', 'Normal', 'Normal', 'High', 'High', 'High'],\n",
        "    'Wind': ['Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Strong', 'Weak'],\n",
        "    'Play': ['No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'No']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "new_instance = {'Outlook': None, 'Temperature': 'Mild', 'Humidity': 'Normal', 'Wind': 'Weak', 'Play': 'Yes'}\n",
        "most_common_outlook = df['Outlook'].mode()[0]\n",
        "df.loc[len(df)] = [most_common_outlook, new_instance['Temperature'], new_instance['Humidity'], new_instance['Wind'], new_instance['Play']]\n",
        "\n",
        "def entropy(attribute):\n",
        "    values, counts = np.unique(attribute, return_counts=True)\n",
        "    probs = counts / len(attribute)\n",
        "    return -np.sum(probs * np.log2(probs))\n",
        "\n",
        "\n",
        "def information_gain(df, feature, target):\n",
        "    total_entropy = entropy(df[target])\n",
        "    values, counts = np.unique(df[feature], return_counts=True)\n",
        "    weighted_entropy = np.sum([(counts[i] / np.sum(counts)) * entropy(df[df[feature] == values[i]][target]) for i in range(len(values))])\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
        "target = 'Play'\n",
        "info_gains = {feature: information_gain(df, feature, target) for feature in features}\n",
        "\n",
        "print(\"Information Gain for each feature:\")\n",
        "for feature, gain in info_gains.items():\n",
        "    print(f\"{feature}: {gain:.3f}\")\n",
        "\n",
        "\n",
        "best_feature = max(info_gains, key=info_gains.get)\n",
        "print(f\"\\nThe best feature to split on is: {best_feature}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX3LXRq_Jx_H",
        "outputId": "bc5af7ab-e82c-4eff-fc1f-134eedc25b43"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Information Gain for each feature:\n",
            "Outlook: 0.094\n",
            "Temperature: 0.004\n",
            "Humidity: 0.559\n",
            "Wind: 0.041\n",
            "\n",
            "The best feature to split on is: Humidity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Day': [1, 2, 7, 8, 9, 10, 11, 12, 14],\n",
        "    'Outlook': ['Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Sunny', 'Sunny'],\n",
        "    'Temperature': ['Hot', 'Hot', 'Mild', 'Mild', 'Mild', 'Mild', 'Mild', 'Mild', 'Mild'],\n",
        "    'Humidity': ['High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal'],\n",
        "    'Wind': ['Weak', 'Strong', 'Strong', 'Weak', 'Strong', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
        "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "def entropy(y):\n",
        "    \"\"\"Calculate the entropy of labels.\"\"\"\n",
        "    proportions = y.value_counts(normalize=True)\n",
        "    return -np.sum(proportions * np.log2(proportions))\n",
        "\n",
        "def information_gain(df, feature, target):\n",
        "    \"\"\"Calculate the information gain of a feature.\"\"\"\n",
        "    # Calculate entropy of the target variable\n",
        "    entropy_before = entropy(df[target])\n",
        "\n",
        "    # Calculate weighted entropy after split\n",
        "    values = df[feature].unique()\n",
        "    entropy_after = 0\n",
        "    for value in values:\n",
        "        subset = df[df[feature] == value]\n",
        "        entropy_after += (len(subset) / len(df)) * entropy(subset[target])\n",
        "\n",
        "    # Information gain\n",
        "    return entropy_before - entropy_after\n",
        "\n",
        "# Calculate information gain for each feature\n",
        "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
        "target = 'PlayTennis'\n",
        "\n",
        "info_gains = {}\n",
        "for feature in features:\n",
        "    info_gains[feature] = information_gain(df, feature, target)\n",
        "\n",
        "# Find the feature with the highest information gain\n",
        "best_feature = max(info_gains, key=info_gains.get)\n",
        "print(f\"The best feature to split on is: {best_feature} with an information gain of {info_gains[best_feature]}\")\n",
        "\n",
        "# Build the tree for the best feature\n",
        "def build_tree(df, feature, target):\n",
        "    \"\"\"Build a simple decision tree based on the best feature.\"\"\"\n",
        "    tree = {}\n",
        "    values = df[feature].unique()\n",
        "    for value in values:\n",
        "        subset = df[df[feature] == value]\n",
        "        if subset[target].nunique() == 1:\n",
        "            tree[value] = subset[target].iloc[0]\n",
        "        else:\n",
        "            # Recursively build the tree for each subset\n",
        "            subtree = {value: build_tree(subset, feature, target)}\n",
        "            tree.update(subtree)\n",
        "    return tree\n",
        "\n",
        "# Build and print the decision tree\n",
        "decision_tree = build_tree(df, best_feature, target)\n",
        "print(\"Decision Tree:\")\n",
        "print(decision_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm9T6ZbeJXKA",
        "outputId": "e34e2517-a3b9-456f-c42a-1d98fcf6e022"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best feature to split on is: Humidity with an information gain of 0.9182958340544896\n",
            "Decision Tree:\n",
            "{'High': 'No', 'Normal': 'Yes'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdlsESiLLWAq",
        "outputId": "004913f0-418c-402d-e854-c3b2fbceaa42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9pRLd9pNUWI"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "train_file = '/content/drive/My Drive/bank/train.csv'\n",
        "test_file = '/content/drive/My Drive/bank/test.csv'\n",
        "train_file = '/content/drive/My Drive/car/train.csv'\n",
        "test_file = '/content/drive/My Drive/car/test.csv'\n"
      ],
      "metadata": {
        "id": "linR3hmFLZyw"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(train_file)\n",
        "test_df = pd.read_csv(test_file)"
      ],
      "metadata": {
        "id": "tq6ZmOV5Lshz"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the data"
      ],
      "metadata": {
        "id": "DWBbWf9GNd5A"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define file paths\n",
        "train_file = '/content/drive/My Drive/car/train.csv'\n",
        "test_file = '/content/drive/My Drive/car/test.csv'\n",
        "\n",
        "# Load the datasets using the specified structure\n",
        "train_df = pd.read_csv(train_file)\n",
        "test_df = pd.read_csv(test_file)\n",
        "\n",
        "# Display the first few rows of the training DataFrame\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "8JOHAp6KNegr",
        "outputId": "a8a81190-3f51-4150-c35d-054c1f7b3d3a"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     low vhigh      4 4.1    big   med    acc\n",
              "0    low  high  5more   4    med  high  vgood\n",
              "1  vhigh   med      2   2    big  high  unacc\n",
              "2   high  high      2   2  small  high  unacc\n",
              "3  vhigh   low      3   2    big   low  unacc\n",
              "4   high  high      3   4    med   low  unacc"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-911097fc-a0e0-456d-b5a7-0f1addc45b0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>low</th>\n",
              "      <th>vhigh</th>\n",
              "      <th>4</th>\n",
              "      <th>4.1</th>\n",
              "      <th>big</th>\n",
              "      <th>med</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>low</td>\n",
              "      <td>high</td>\n",
              "      <td>5more</td>\n",
              "      <td>4</td>\n",
              "      <td>med</td>\n",
              "      <td>high</td>\n",
              "      <td>vgood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>med</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>big</td>\n",
              "      <td>high</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high</td>\n",
              "      <td>high</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>high</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>low</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>big</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>high</td>\n",
              "      <td>high</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-911097fc-a0e0-456d-b5a7-0f1addc45b0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-911097fc-a0e0-456d-b5a7-0f1addc45b0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-911097fc-a0e0-456d-b5a7-0f1addc45b0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-576d5f31-078e-4c0b-83ae-86c79241debe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-576d5f31-078e-4c0b-83ae-86c79241debe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-576d5f31-078e-4c0b-83ae-86c79241debe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 999,\n  \"fields\": [\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"vhigh\",\n          \"med\",\n          \"low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vhigh\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"med\",\n          \"vhigh\",\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2\",\n          \"4\",\n          \"5more\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"4.1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"4\",\n          \"2\",\n          \"more\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"big\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"med\",\n          \"big\",\n          \"small\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"med\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"high\",\n          \"low\",\n          \"med\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"unacc\",\n          \"good\",\n          \"vgood\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "Uno0lHQsNmwl",
        "outputId": "4995661e-0dc2-48d0-d48b-daee16fcda4d"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   vhigh   high  5more  2  small  low  unacc\n",
              "0    low    low  5more  2  small  med  unacc\n",
              "1    low  vhigh      4  2    med  low  unacc\n",
              "2   high  vhigh      3  4    med  med  unacc\n",
              "3  vhigh    low      4  4    med  low  unacc\n",
              "4   high  vhigh  5more  4    med  low  unacc"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-791147ea-1ca5-4c38-8f35-bfa763636e88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vhigh</th>\n",
              "      <th>high</th>\n",
              "      <th>5more</th>\n",
              "      <th>2</th>\n",
              "      <th>small</th>\n",
              "      <th>low</th>\n",
              "      <th>unacc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>5more</td>\n",
              "      <td>2</td>\n",
              "      <td>small</td>\n",
              "      <td>med</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>low</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>high</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>med</td>\n",
              "      <td>med</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vhigh</td>\n",
              "      <td>low</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>high</td>\n",
              "      <td>vhigh</td>\n",
              "      <td>5more</td>\n",
              "      <td>4</td>\n",
              "      <td>med</td>\n",
              "      <td>low</td>\n",
              "      <td>unacc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-791147ea-1ca5-4c38-8f35-bfa763636e88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-791147ea-1ca5-4c38-8f35-bfa763636e88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-791147ea-1ca5-4c38-8f35-bfa763636e88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-08edb6ff-19e0-4647-b777-d81c8cf8607d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08edb6ff-19e0-4647-b777-d81c8cf8607d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-08edb6ff-19e0-4647-b777-d81c8cf8607d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 727,\n  \"fields\": [\n    {\n      \"column\": \"vhigh\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"high\",\n          \"med\",\n          \"low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"vhigh\",\n          \"high\",\n          \"low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5more\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"4\",\n          \"2\",\n          \"5more\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2\",\n          \"4\",\n          \"more\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"small\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"small\",\n          \"med\",\n          \"big\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"med\",\n          \"low\",\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unacc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"acc\",\n          \"good\",\n          \"unacc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "car_train_file = '/content/drive/My Drive/car/train.csv'\n",
        "car_test_file = '/content/drive/My Drive/car/test.csv'\n",
        "bank_train_file = '/content/drive/My Drive/bank/train.csv'\n",
        "bank_test_file = '/content/drive/My Drive/bank/test.csv'"
      ],
      "metadata": {
        "id": "0OWfaeEONnnF"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_train_df.isnull().sum()\n",
        "car_test_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "siVWJYzb0rPD",
        "outputId": "59913d6e-5dd8-4384-916d-ab9a92c9e2ce"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vhigh    0\n",
              "high     0\n",
              "5more    0\n",
              "2        0\n",
              "small    0\n",
              "low      0\n",
              "unacc    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>vhigh</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5more</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>small</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unacc</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(car_train_df.columns)\n",
        "print(car_test_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS9o-8h72E7G",
        "outputId": "461d1832-5317-4ba9-e569-6a9affb746eb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['low', 'vhigh', '4', '4.1', 'big', 'med', 'acc'], dtype='object')\n",
            "Index(['vhigh', 'high', '5more', '2', 'small', 'low', 'unacc'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "car_X_train = pd.get_dummies(car_train_df.drop('acc', axis=1))\n",
        "car_y_train = car_train_df['acc']\n",
        "\n",
        "car_X_test = pd.get_dummies(car_test_df.drop('unacc', axis=1))\n",
        "car_y_test = car_test_df['unacc']"
      ],
      "metadata": {
        "id": "Xo_6-fcC1RSw"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_X_train, car_X_test = car_X_train.align(car_X_test, join='left', axis=1, fill_value=0)"
      ],
      "metadata": {
        "id": "fdr3Q1JS2TnN"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "car_train_df = pd.read_csv(car_train_file)\n",
        "car_test_df = pd.read_csv(car_test_file)\n",
        "bank_train_df = pd.read_csv(bank_train_file)\n",
        "bank_test_df = pd.read_csv(bank_test_file)"
      ],
      "metadata": {
        "id": "DdEalU1kP5pW"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate entropy\n",
        "def entropy(y):\n",
        "    proportions = y.value_counts(normalize=True)\n",
        "    return -np.sum(proportions * np.log2(proportions))\n",
        "\n",
        "# Define a function to calculate information gain\n",
        "def information_gain(X, y, feature):\n",
        "    original_entropy = entropy(y)\n",
        "    values = X[feature].unique()\n",
        "    weighted_entropy = 0\n",
        "    for value in values:\n",
        "        subset_y = y[X[feature] == value]\n",
        "        weighted_entropy += (len(subset_y) / len(y)) * entropy(subset_y)\n",
        "    return original_entropy - weighted_entropy\n",
        "\n",
        "# Define a function to calculate gini index\n",
        "def gini_index(y):\n",
        "    proportions = y.value_counts(normalize=True)\n",
        "    return 1 - np.sum(proportions ** 2)\n",
        "\n",
        "# Define a function to calculate gini gain\n",
        "def gini_gain(X, y, feature):\n",
        "    original_gini = gini_index(y)\n",
        "    values = X[feature].unique()\n",
        "    weighted_gini = 0\n",
        "    for value in values:\n",
        "        subset_y = y[X[feature] == value]\n",
        "        weighted_gini += (len(subset_y) / len(y)) * gini_index(subset_y)\n",
        "    return original_gini - weighted_gini\n",
        "\n",
        "# Define the ID3 algorithm with heuristics\n",
        "class DecisionTreeID3:\n",
        "    def __init__(self, max_depth=None, criterion='information_gain'):\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if len(y.unique()) == 1:\n",
        "            return y.mode()[0]\n",
        "\n",
        "        if self.max_depth and depth >= self.max_depth:\n",
        "            return y.mode()[0]\n",
        "\n",
        "        if X.empty:\n",
        "            return y.mode()[0]\n",
        "\n",
        "        best_feature = self._choose_best_feature(X, y)\n",
        "        tree = {best_feature: {}}\n",
        "        for value in X[best_feature].unique():\n",
        "            subset_X = X[X[best_feature] == value].drop(best_feature, axis=1)\n",
        "            subset_y = y[X[best_feature] == value]\n",
        "            tree[best_feature][value] = self._build_tree(subset_X, subset_y, depth + 1)\n",
        "        return tree\n",
        "\n",
        "    def _choose_best_feature(self, X, y):\n",
        "        if self.criterion == 'information_gain':\n",
        "            return max(X.columns, key=lambda feature: information_gain(X, y, feature))\n",
        "        elif self.criterion == 'gini_index':\n",
        "            return max(X.columns, key=lambda feature: gini_gain(X, y, feature))\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported criterion: {}\".format(self.criterion))\n",
        "\n",
        "    def predict(self, X):\n",
        "        return X.apply(lambda row: self._predict_single(row, self.tree), axis=1)\n",
        "\n",
        "    def _predict_single(self, row, tree):\n",
        "        if not isinstance(tree, dict):\n",
        "            return tree\n",
        "\n",
        "        feature = list(tree.keys())[0]\n",
        "        value = row[feature]\n",
        "        subtree = tree[feature].get(value, None)\n",
        "\n",
        "        if subtree is None:\n",
        "            return None\n",
        "\n",
        "        return self._predict_single(row, subtree)"
      ],
      "metadata": {
        "id": "Fovz03kUQBC1"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the training and test datasets\n",
        "car_X_train = pd.get_dummies(car_train_df.drop('acc', axis=1))\n",
        "car_y_train = car_train_df['acc']\n",
        "\n",
        "car_X_test = pd.get_dummies(car_test_df.drop('unacc', axis=1))\n",
        "car_y_test = car_test_df['unacc']\n",
        "\n",
        "# Ensure that the training and test sets have the same columns\n",
        "car_X_test = car_X_test.reindex(columns=car_X_train.columns, fill_value=0)\n",
        "\n",
        "# Define a function to evaluate the model\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    train_predictions = model.predict(X_train)\n",
        "    test_predictions = model.predict(X_test)\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "# Training and testing decision tree on car dataset\n",
        "depths = range(1, 7)\n",
        "criteria = ['information_gain', 'gini_index']\n",
        "\n",
        "results = []\n",
        "\n",
        "for criterion in criteria:\n",
        "    for depth in depths:\n",
        "        model = DecisionTreeID3(max_depth=depth, criterion=criterion)\n",
        "        train_accuracy, test_accuracy = evaluate_model(model, car_X_train, car_y_train, car_X_test, car_y_test)\n",
        "        results.append({'Depth': depth, 'Criterion': criterion, 'Train Accuracy': train_accuracy, 'Test Accuracy': test_accuracy})\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPCNQ-5qQLIN",
        "outputId": "3ade1ba4-93e7-40d9-8271-18fc50e769cd"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Depth         Criterion  Train Accuracy  Test Accuracy\n",
            "0       1  information_gain        0.698699       0.702889\n",
            "1       2  information_gain        0.777778       0.222834\n",
            "2       3  information_gain        0.807808       0.374140\n",
            "3       4  information_gain        0.807808       0.257221\n",
            "4       5  information_gain        0.865866       0.257221\n",
            "5       6  information_gain        0.880881       0.257221\n",
            "6       1        gini_index        0.698699       0.702889\n",
            "7       2        gini_index        0.777778       0.222834\n",
            "8       3        gini_index        0.807808       0.374140\n",
            "9       4        gini_index        0.823824       0.331499\n",
            "10      5        gini_index        0.858859       0.257221\n",
            "11      6        gini_index        0.898899       0.299862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    train_predictions = model.predict(X_train)\n",
        "    test_predictions = model.predict(X_test)\n",
        "\n",
        "    # Debugging print statements\n",
        "    print(\"Train predictions:\", train_predictions.unique())\n",
        "    print(\"Test predictions:\", test_predictions.unique())\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "    return train_accuracy, test_accuracy"
      ],
      "metadata": {
        "id": "K5w52GOx6mRm"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bank_train_df.columns)\n",
        "print(bank_test_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqzr5moy4U9C",
        "outputId": "8459039c-f3b6-4335-dcfb-2800608c1511"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['41', 'services', 'married', 'secondary', 'no', '0', 'yes', 'no.1',\n",
            "       'unknown', '5', 'may', '114', '2', '-1', '0.1', 'unknown.1', 'no.2'],\n",
            "      dtype='object')\n",
            "Index(['41', 'management', 'single', 'secondary', 'no', '764', 'no.1', 'no.2',\n",
            "       'cellular', '12', 'jun', '230', '2', '-1', '0', 'unknown', 'no.3'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bank_train_df.head())\n",
        "print(bank_test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZs233cn4oyA",
        "outputId": "e276553a-1504-443e-d2b4-f2bbc33c559a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   41     services   married  secondary  no     0  yes no.1   unknown   5  \\\n",
            "0  48  blue-collar    single  secondary  no   312  yes  yes  cellular   3   \n",
            "1  55   technician   married  secondary  no  1938   no  yes  cellular  18   \n",
            "2  54       admin.   married   tertiary  no    59  yes   no  cellular  10   \n",
            "3  34   management    single   tertiary  no  2646   no   no  cellular  14   \n",
            "4  49       admin.  divorced  secondary  no  1709  yes   no   unknown  12   \n",
            "\n",
            "   may  114  2   -1  0.1 unknown.1 no.2  \n",
            "0  feb  369  2   -1    0   unknown   no  \n",
            "1  aug  193  1  386    3   success  yes  \n",
            "2  jul  268  1   -1    0   unknown   no  \n",
            "3  apr  142  1   -1    0   unknown  yes  \n",
            "4  jun  106  1   -1    0   unknown   no  \n",
            "   41    management   single  secondary  no   764 no.1 no.2   cellular  12  \\\n",
            "0  39   blue-collar  married  secondary  no    49  yes   no   cellular  14   \n",
            "1  60       retired  married    primary  no     0   no   no  telephone  30   \n",
            "2  31  entrepreneur   single   tertiary  no   247  yes  yes    unknown   2   \n",
            "3  26       student   single    unknown  no  2020   no   no  telephone  28   \n",
            "4  58     housemaid  married    primary  no     0  yes   no  telephone   9   \n",
            "\n",
            "   jun  230  2   -1  0  unknown no.3  \n",
            "0  may  566  1  370  2  failure   no  \n",
            "1  jul  130  3   -1  0  unknown   no  \n",
            "2  jun  273  1   -1  0  unknown   no  \n",
            "3  jan   42  3   -1  0  unknown   no  \n",
            "4  jul  148  1   -1  0  unknown   no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    train_predictions = model.predict(X_train)\n",
        "    test_predictions = model.predict(X_test)\n",
        "\n",
        "    # Clean None values from predictions and true values\n",
        "    train_predictions = pd.Series(train_predictions).replace({None: 'unknown'})\n",
        "    test_predictions = pd.Series(test_predictions).replace({None: 'unknown'})\n",
        "    y_train = y_train.replace({None: 'unknown'})\n",
        "    y_test = y_test.replace({None: 'unknown'})\n",
        "\n",
        "    # Debugging print statements\n",
        "    print(\"Train predictions:\", train_predictions.unique())\n",
        "    print(\"Test predictions:\", test_predictions.unique())\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "# Ensure there are no None values in y_train and y_test\n",
        "bank_y_train = bank_y_train.replace({None: 'unknown'})\n",
        "bank_y_test = bank_y_test.replace({None: 'unknown'})\n",
        "\n",
        "# Continue with training and evaluation\n",
        "results_bank = []\n",
        "\n",
        "for criterion in criteria:\n",
        "    for depth in range(1, 17):\n",
        "        model = DecisionTreeID3(max_depth=depth, criterion=criterion)\n",
        "        train_accuracy, test_accuracy = evaluate_model(model, bank_X_train, bank_y_train, bank_X_test, bank_y_test)\n",
        "        results_bank.append({'Depth': depth, 'Criterion': criterion, 'Train Accuracy': train_accuracy, 'Test Accuracy': test_accuracy})\n",
        "\n",
        "# Display results\n",
        "results_bank_df = pd.DataFrame(results_bank)\n",
        "print(results_bank_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heHDh7uOQSxr",
        "outputId": "5d169365-cc13-48a7-c7f4-43af17a7fa7e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['no']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['no']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "Train predictions: ['no' 'yes']\n",
            "Test predictions: ['unknown' 'no' 'yes']\n",
            "    Depth         Criterion  Train Accuracy  Test Accuracy\n",
            "0       1  information_gain        0.928386       0.875175\n",
            "1       2  information_gain        0.999600       0.073415\n",
            "2       3  information_gain        1.000000       0.073415\n",
            "3       4  information_gain        1.000000       0.073415\n",
            "4       5  information_gain        1.000000       0.073415\n",
            "5       6  information_gain        1.000000       0.073415\n",
            "6       7  information_gain        1.000000       0.073415\n",
            "7       8  information_gain        1.000000       0.073415\n",
            "8       9  information_gain        1.000000       0.073415\n",
            "9      10  information_gain        1.000000       0.073415\n",
            "10     11  information_gain        1.000000       0.073415\n",
            "11     12  information_gain        1.000000       0.073415\n",
            "12     13  information_gain        1.000000       0.073415\n",
            "13     14  information_gain        1.000000       0.073415\n",
            "14     15  information_gain        1.000000       0.073415\n",
            "15     16  information_gain        1.000000       0.073415\n",
            "16      1        gini_index        0.928386       0.875175\n",
            "17      2        gini_index        0.999600       0.073415\n",
            "18      3        gini_index        1.000000       0.073415\n",
            "19      4        gini_index        1.000000       0.073415\n",
            "20      5        gini_index        1.000000       0.073415\n",
            "21      6        gini_index        1.000000       0.073415\n",
            "22      7        gini_index        1.000000       0.073415\n",
            "23      8        gini_index        1.000000       0.073415\n",
            "24      9        gini_index        1.000000       0.073415\n",
            "25     10        gini_index        1.000000       0.073415\n",
            "26     11        gini_index        1.000000       0.073415\n",
            "27     12        gini_index        1.000000       0.073415\n",
            "28     13        gini_index        1.000000       0.073415\n",
            "29     14        gini_index        1.000000       0.073415\n",
            "30     15        gini_index        1.000000       0.073415\n",
            "31     16        gini_index        1.000000       0.073415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the column names of the training and test data\n",
        "print(\"Car Training Data Columns:\", car_train_df.columns)\n",
        "print(\"Car Test Data Columns:\", car_test_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbj1D4uxOrmk",
        "outputId": "3231c734-40f1-4437-c78e-0133527c6c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Car Training Data Columns: Index(['low', 'vhigh', '4', '4.1', 'big', 'med', 'acc'], dtype='object')\n",
            "Car Test Data Columns: Index(['vhigh', 'high', '5more', '2', 'small', 'low', 'unacc'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "car_train_df = pd.read_csv(car_train_file)\n",
        "car_test_df = pd.read_csv(car_test_file)\n",
        "\n",
        "# Print column names to verify\n",
        "print(\"Car Training Data Columns:\", car_train_df.columns)\n",
        "print(\"Car Test Data Columns:\", car_test_df.columns)\n",
        "\n",
        "# Define a function to calculate entropy\n",
        "def entropy(y):\n",
        "    proportions = y.value_counts(normalize=True)\n",
        "    return -np.sum(proportions * np.log2(proportions))\n",
        "\n",
        "# Define a function to calculate information gain\n",
        "def information_gain(X, y, feature):\n",
        "    original_entropy = entropy(y)\n",
        "    values = X[feature].unique()\n",
        "    weighted_entropy = 0\n",
        "    for value in values:\n",
        "        subset_y = y[X[feature] == value]\n",
        "        weighted_entropy += (len(subset_y) / len(y)) * entropy(subset_y)\n",
        "    return original_entropy - weighted_entropy\n",
        "\n",
        "# Define a function to calculate gini index\n",
        "def gini_index(y):\n",
        "    proportions = y.value_counts(normalize=True)\n",
        "    return 1 - np.sum(proportions ** 2)\n",
        "\n",
        "# Define a function to calculate gini gain\n",
        "def gini_gain(X, y, feature):\n",
        "    original_gini = gini_index(y)\n",
        "    values = X[feature].unique()\n",
        "    weighted_gini = 0\n",
        "    for value in values:\n",
        "        subset_y = y[X[feature] == value]\n",
        "        weighted_gini += (len(subset_y) / len(y)) * gini_index(subset_y)\n",
        "    return original_gini - weighted_gini\n",
        "\n",
        "# Define the ID3 algorithm with heuristics\n",
        "class DecisionTreeID3:\n",
        "    def __init__(self, max_depth=None, criterion='information_gain'):\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if len(y.unique()) == 1:\n",
        "            return y.mode()[0]\n",
        "\n",
        "        if self.max_depth and depth >= self.max_depth:\n",
        "            return y.mode()[0]\n",
        "\n",
        "        if X.empty:\n",
        "            return y.mode()[0]\n",
        "\n",
        "        best_feature = self._choose_best_feature(X, y)\n",
        "        tree = {best_feature: {}}\n",
        "        for value in X[best_feature].unique():\n",
        "            subset_X = X[X[best_feature] == value].drop(best_feature, axis=1)\n",
        "            subset_y = y[X[best_feature] == value]\n",
        "            tree[best_feature][value] = self._build_tree(subset_X, subset_y, depth + 1)\n",
        "        return tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78qfPkNwQzRW",
        "outputId": "bc496318-ecfa-4bc8-9a35-75a9f9f753f8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Car Training Data Columns: Index(['low', 'vhigh', '4', '4.1', 'big', 'med', 'acc'], dtype='object')\n",
            "Car Test Data Columns: Index(['vhigh', 'high', '5more', '2', 'small', 'low', 'unacc'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. ID3 Algorithm with Categorical Attributes"
      ],
      "metadata": {
        "id": "U7VInPeENz9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from typing import Any, Dict, Tuple, Union\n",
        "\n",
        "class DecisionTreeID3:\n",
        "    def __init__(self, max_depth: int = None, criterion: str = 'information_gain'):\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
        "        self.tree = self._fit(X, y, depth=0)\n",
        "\n",
        "    def _fit(self, X: pd.DataFrame, y: pd.Series, depth: int) -> Dict[str, Any]:\n",
        "        if len(set(y)) == 1:\n",
        "            return {'label': y.iloc[0]}\n",
        "\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return {'label': y.mode()[0]}\n",
        "\n",
        "        best_attribute = self._select_best_attribute(X, y)\n",
        "        tree = {best_attribute: {}}\n",
        "        for value in X[best_attribute].unique():\n",
        "            sub_X = X[X[best_attribute] == value].drop(columns=[best_attribute])\n",
        "            sub_y = y[X[best_attribute] == value]\n",
        "            tree[best_attribute][value] = self._fit(sub_X, sub_y, depth + 1)\n",
        "\n",
        "        return tree\n",
        "\n",
        "    def _select_best_attribute(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
        "        if self.criterion == 'information_gain':\n",
        "            return self._best_information_gain(X, y)\n",
        "        elif self.criterion == 'gini_index':\n",
        "            return self._best_gini_index(X, y)\n",
        "        elif self.criterion == 'majority_error':\n",
        "            return self._best_majority_error(X, y)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown criterion\")\n",
        "\n",
        "    def _best_information_gain(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
        "        base_entropy = self._entropy(y)\n",
        "        best_gain = 0\n",
        "        best_attribute = None\n",
        "        for attribute in X.columns:\n",
        "            new_entropy = 0\n",
        "            for value in X[attribute].unique():\n",
        "                sub_y = y[X[attribute] == value]\n",
        "                new_entropy += (len(sub_y) / len(y)) * self._entropy(sub_y)\n",
        "            info_gain = base_entropy - new_entropy\n",
        "            if info_gain > best_gain:\n",
        "                best_gain = info_gain\n",
        "                best_attribute = attribute\n",
        "        return best_attribute\n",
        "\n",
        "    def _best_gini_index(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
        "        best_gini = float('inf')\n",
        "        best_attribute = None\n",
        "        for attribute in X.columns:\n",
        "            gini = 0\n",
        "            for value in X[attribute].unique():\n",
        "                sub_y = y[X[attribute] == value]\n",
        "                prob = len(sub_y) / len(y)\n",
        "                gini += prob * (1 - sum([(sub_y.value_counts() / len(sub_y))**2]))\n",
        "            if gini < best_gini:\n",
        "                best_gini = gini\n",
        "                best_attribute = attribute\n",
        "        return best_attribute\n",
        "\n",
        "    def _best_majority_error(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
        "        best_error = float('inf')\n",
        "        best_attribute = None\n",
        "        for attribute in X.columns:\n",
        "            error = 0\n",
        "            for value in X[attribute].unique():\n",
        "                sub_y = y[X[attribute] == value]\n",
        "                majority_class = sub_y.mode()[0]\n",
        "                error += (len(sub_y) / len(y)) * (1 - (sub_y == majority_class).mean())\n",
        "            if error < best_error:\n",
        "                best_error = error\n",
        "                best_attribute = attribute\n",
        "        return best_attribute\n",
        "\n",
        "    def _entropy(self, y: pd.Series) -> float:\n",
        "        probs = y.value_counts(normalize=True)\n",
        "        return -sum(probs * np.log2(probs + 1e-9))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return X.apply(self._predict_row, axis=1)\n",
        "\n",
        "    def _predict_row(self, row: pd.Series) -> Any:\n",
        "        tree = self.tree\n",
        "        while isinstance(tree, dict):\n",
        "            attribute = list(tree.keys())[0]\n",
        "            value = row[attribute]\n",
        "            tree = tree[attribute].get(value, {'label': 'unknown'})\n",
        "        return tree['label']\n"
      ],
      "metadata": {
        "id": "52Dtr5LoNWxD"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Evaluate Decision Trees for Car Datase"
      ],
      "metadata": {
        "id": "ialwVqC7NnfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from typing import Any, Dict, Tuple\n",
        "\n",
        "class DecisionTreeID3:\n",
        "    def __init__(self, max_depth: int = None, criterion: str = 'information_gain'):\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "        self.numerical_attributes = []\n",
        "        self.categorical_attributes = []\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
        "        self.numerical_attributes = [col for col in X.columns if X[col].dtype in [np.float64, np.int64]]\n",
        "        self.categorical_attributes = [col for col in X.columns if X[col].dtype == object]\n",
        "        self.tree = self._fit(X, y, depth=0)\n",
        "        print(\"Decision Tree Structure:\", self.tree)  # Debug print\n",
        "\n",
        "    def _fit(self, X: pd.DataFrame, y: pd.Series, depth: int) -> Dict[str, Any]:\n",
        "        if len(set(y)) == 1:\n",
        "            return {'label': y.iloc[0]}\n",
        "\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return {'label': y.mode()[0]}\n",
        "\n",
        "        best_attribute = self._select_best_attribute(X, y)\n",
        "        tree = {best_attribute: {}}\n",
        "\n",
        "        if best_attribute in self.numerical_attributes:\n",
        "            median = X[best_attribute].median()\n",
        "            for condition in [lambda x: x <= median, lambda x: x > median]:\n",
        "                sub_X = X[X[best_attribute].apply(condition)].drop(columns=[best_attribute])\n",
        "                sub_y = y[X[best_attribute].apply(condition)]\n",
        "                tree[best_attribute][condition.__name__] = self._fit(sub_X, sub_y, depth + 1)\n",
        "        else:\n",
        "            for value in X[best_attribute].unique():\n",
        "                sub_X = X[X[best_attribute] == value].drop(columns=[best_attribute])\n",
        "                sub_y = y[X[best_attribute] == value]\n",
        "                tree[best_attribute][value] = self._fit(sub_X, sub_y, depth + 1)\n",
        "\n",
        "        return tree\n",
        "\n",
        "    def _select_best_attribute(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
        "        if self.criterion == 'information_gain':\n",
        "            return self._best_information_gain(X, y)\n",
        "        elif self.criterion == 'gini_index':\n",
        "            return self._best_gini_index(X, y)\n",
        "        elif self.criterion == 'majority_error':\n",
        "            return self._best_majority_error(X, y)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown criterion\")\n",
        "\n",
        "    def _best_information_gain(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
        "        base_entropy = self._entropy(y)\n",
        "        best_gain = 0\n",
        "        best_attribute = None\n",
        "        for attribute in X.columns:\n",
        "            new_entropy = 0\n",
        "            for value in X[attribute].unique():\n",
        "                sub_y = y[X[attribute] == value]\n",
        "                new_entropy += (len(sub_y) / len(y)) * self._entropy(sub_y)\n",
        "            info_gain = base_entropy - new_entropy\n",
        "            if info_gain > best_gain:\n",
        "                best_gain = info_gain\n",
        "                best_attribute = attribute\n",
        "        return best_attribute\n",
        "\n",
        "    def _best_gini_index(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
        "        best_gini = float('inf')\n",
        "        best_attribute = None\n",
        "        for attribute in X.columns:\n",
        "            gini = 0\n",
        "            for value in X[attribute].unique():\n",
        "                sub_y = y[X[attribute] == value]\n",
        "                prob = len(sub_y) / len(y)\n",
        "                gini += prob * (1 - sum([(sub_y.value_counts() / len(sub_y))**2]))\n",
        "            if gini < best_gini:\n",
        "                best_gini = gini\n",
        "                best_attribute = attribute\n",
        "        return best_attribute\n",
        "\n",
        "    def _best_majority_error(self, X: pd.DataFrame, y: pd.Series) -> str:\n",
        "        best_error = float('inf')\n",
        "        best_attribute = None\n",
        "        for attribute in X.columns:\n",
        "            error = 0\n",
        "            for value in X[attribute].unique():\n",
        "                sub_y = y[X[attribute] == value]\n",
        "                majority_class = sub_y.mode()[0]\n",
        "                error += (len(sub_y) / len(y)) * (1 - (sub_y == majority_class).mean())\n",
        "            if error < best_error:\n",
        "                best_error = error\n",
        "                best_attribute = attribute\n",
        "        return best_attribute\n",
        "\n",
        "    def _entropy(self, y: pd.Series) -> float:\n",
        "        probs = y.value_counts(normalize=True)\n",
        "        return -sum(probs * np.log2(probs + 1e-9))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return X.apply(self._predict_row, axis=1)\n",
        "\n",
        "    def _predict_row(self, row: pd.Series) -> Any:\n",
        "        tree = self.tree\n",
        "        while isinstance(tree, dict):\n",
        "            attribute = list(tree.keys())[0]\n",
        "            value = row[attribute]\n",
        "            if attribute in self.numerical_attributes:\n",
        "                condition = lambda x: x <= row[attribute] if 'le' in list(tree[attribute].keys())[0] else lambda x: x > row[attribute]\n",
        "                next_node = tree[attribute].get(condition.__name__)\n",
        "            else:\n",
        "                next_node = tree[attribute].get(value)\n",
        "\n",
        "            if isinstance(next_node, dict):\n",
        "                tree = next_node\n",
        "            else:\n",
        "                return next_node.get('label', 'unknown')\n",
        "        return tree.get('label', 'unknown')\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    train_predictions = model.predict(X_train)\n",
        "    test_predictions = model.predict(X_test)\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "# Load car dataset with the correct paths\n",
        "car_train_df = pd.read_csv('/content/drive/My Drive/car/train.csv')\n",
        "car_test_df = pd.read_csv('/content/drive/My Drive/car/test.csv')\n",
        "\n",
        "# Print column names to check if 'acc' is present\n",
        "print(\"Training Data Columns:\", car_train_df.columns)\n",
        "print(\"Test Data Columns:\", car_test_df.columns)\n",
        "\n",
        "# Ensure the 'acc' column exists in the training dataset and map to the test dataset\n",
        "if 'acc' not in car_train_df.columns:\n",
        "    raise KeyError(\"'acc' column not found in the training dataset\")\n",
        "\n",
        "# Map the training columns to the test dataset columns\n",
        "car_X_train = car_train_df.drop('acc', axis=1)\n",
        "car_y_train = car_train_df['acc']\n",
        "car_X_test = car_test_df.copy()\n",
        "car_y_test = car_test_df['unacc']  # Assuming 'unacc' is the label column in the test set\n",
        "\n",
        "# Align the columns of the test dataset with the training dataset\n",
        "car_X_test = car_X_test.reindex(columns=car_X_train.columns, fill_value='missing')\n",
        "\n",
        "depths = range(1, 7)\n",
        "criteria = ['information_gain', 'gini_index', 'majority_error']\n",
        "\n",
        "results = []\n",
        "\n",
        "for criterion in criteria:\n",
        "    for depth in depths:\n",
        "        model = DecisionTreeID3(max_depth=depth, criterion=criterion)\n",
        "        train_accuracy, test_accuracy = evaluate_model(model, car_X_train, car_y_train, car_X_test, car_y_test)\n",
        "        results.append({'Depth': depth, 'Criterion': criterion, 'Train Accuracy': train_accuracy, 'Test Accuracy': test_accuracy})\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "COuFsYZfNXmy",
        "outputId": "49a9c281-6ea4-4267-eb7a-76842189a46a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Columns: Index(['low', 'vhigh', '4', '4.1', 'big', 'med', 'acc'], dtype='object')\n",
            "Test Data Columns: Index(['vhigh', 'high', '5more', '2', 'small', 'low', 'unacc'], dtype='object')\n",
            "Decision Tree Structure: {'med': {'high': {'label': 'unacc'}, 'low': {'label': 'unacc'}, 'med': {'label': 'unacc'}}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-9461b65ae536>\u001b[0m in \u001b[0;36m<cell line: 155>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeID3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcar_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcar_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcar_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcar_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Criterion'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test Accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-9461b65ae536>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mtrain_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-9461b65ae536>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10032\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10033\u001b[0m         )\n\u001b[0;32m> 10034\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10036\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-9461b65ae536>\u001b[0m in \u001b[0;36m_predict_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mattribute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerical_attributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'le'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Modify for Numerical Attributes and Missing Values.\n",
        "\n",
        "a. Numerical Attributes"
      ],
      "metadata": {
        "id": "T6BUX1_iN3d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeID3:\n",
        "    def __init__(self, max_depth: int = None, criterion: str = 'information_gain'):\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "        self.numerical_attributes = []\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
        "        self.numerical_attributes = [col for col in X.columns if X[col].dtype in [np.float64, np.int64]]\n",
        "        self.tree = self._fit(X, y, depth=0)\n",
        "\n",
        "    def _fit(self, X: pd.DataFrame, y: pd.Series, depth: int) -> Dict[str, Any]:\n",
        "        if len(set(y)) == 1:\n",
        "            return {'label': y.iloc[0]}\n",
        "\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return {'label': y.mode()[0]}\n",
        "\n",
        "        best_attribute = self._select_best_attribute(X, y)\n",
        "        tree = {best_attribute: {}}\n",
        "        if best_attribute in self.numerical_attributes:\n",
        "            median = X[best_attribute].median()\n",
        "            for condition in [lambda x: x <= median, lambda x: x > median]:\n",
        "                sub_X = X[X[best_attribute].apply(condition)].drop(columns=[best_attribute])\n",
        "                sub_y = y[X[best_attribute].apply(condition)]\n",
        "                tree[best_attribute][condition.__name__] = self._fit(sub_X, sub_y, depth + 1)\n",
        "        else:\n",
        "            for value in X[best_attribute].unique():\n",
        "                sub_X = X[X[best_attribute] == value].drop(columns=[best_attribute])\n",
        "                sub_y = y[X[best_attribute] == value]\n",
        "                tree[best_attribute][value] = self._fit(sub_X, sub_y, depth + 1)\n",
        "\n",
        "        return tree\n",
        "\n",
        "    def _predict_row(self, row: pd.Series) -> Any:\n",
        "        tree = self.tree\n",
        "        while isinstance(tree, dict):\n",
        "            attribute = list(tree.keys())[0]\n",
        "            value = row[attribute]\n",
        "            if attribute in self.numerical_attributes:\n",
        "                condition = lambda x: x <= row[attribute] if 'le' in list(tree[attribute].keys())[0] else lambda x: x > row[attribute]\n",
        "                tree = tree[attribute].get(condition.__name__, {'label': 'unknown'})\n",
        "            else:\n",
        "                tree = tree[attribute].get(value, {'label': 'unknown'})\n",
        "        return tree['label']"
      ],
      "metadata": {
        "id": "aGxpZsEPNkSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Missing Values and Evaluation for Bank Dataset"
      ],
      "metadata": {
        "id": "5EEm4_I6OBcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load bank dataset\n",
        "bank_train_df = pd.read_csv('path_to_bank_train.csv')\n",
        "bank_test_df = pd.read_csv('path_to_bank_test.csv')\n",
        "\n",
        "# Handle missing values\n",
        "def handle_missing_values(df):\n",
        "    for column in df.columns:\n",
        "        if df[column].dtype == 'object':\n",
        "            df[column].replace('unknown', np.nan, inplace=True)\n",
        "            df[column].fillna(df[column].mode()[0], inplace=True)\n",
        "    return df\n",
        "\n",
        "bank_train_df = handle_missing_values(bank_train_df)\n",
        "bank_test_df = handle_missing_values(bank_test_df)\n",
        "\n",
        "# Prepare data\n",
        "bank_X_train = bank_train_df.drop('y', axis=1)\n",
        "bank_y_train = bank_train_df['y']\n",
        "bank_X_test = bank_test_df.drop('y', axis=1)\n",
        "bank_y_test = bank_test_df['y']\n",
        "\n",
        "results_bank = []\n",
        "\n",
        "for criterion in criteria:\n",
        "    for depth in range(1, 17):\n",
        "        model = DecisionTreeID3(max_depth=depth, criterion=criterion)\n",
        "        train_accuracy, test_accuracy = evaluate_model(model, bank_X_train, bank_y_train, bank_X_test, bank_y_test)\n",
        "        results_bank.append({'Depth': depth, 'Criterion': criterion, 'Train Accuracy': train_accuracy, 'Test Accuracy': test_accuracy})\n",
        "\n",
        "# Display results\n",
        "results_bank_df = pd.DataFrame(results_bank)\n",
        "print(results_bank_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "4UPgVkHuN_WY",
        "outputId": "6b01d8e4-d6b7-4d04-dae7-e30c1bd39965"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path_to_bank_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-273afb15b1eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load bank dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbank_train_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path_to_bank_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbank_test_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path_to_bank_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Handle missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_bank_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Data Columns:\", car_train_df.columns)\n",
        "print(\"Test Data Columns:\", car_test_df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1xnl79ISMLE",
        "outputId": "777510aa-aba3-48d6-d4ff-e7f920ac0d83"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Columns: Index(['low', 'vhigh', '4', '4.1', 'big', 'med', 'acc'], dtype='object')\n",
            "Test Data Columns: Index(['vhigh', 'high', '5more', '2', 'small', 'low', 'unacc'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "car_train_df.columns = car_train_df.columns.str.strip()\n",
        "car_test_df.columns = car_test_df.columns.str.strip()"
      ],
      "metadata": {
        "id": "RNJVTaYCSMwv"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load car dataset with the correct paths\n",
        "car_train_df = pd.read_csv('/content/drive/My Drive/car/train.csv')\n",
        "car_test_df = pd.read_csv('/content/drive/My Drive/car/test.csv')\n",
        "\n",
        "# Debug column names\n",
        "print(\"Training Data Columns:\", car_train_df.columns)\n",
        "print(\"Test Data Columns:\", car_test_df.columns)\n",
        "\n",
        "# Strip any extra spaces from column names\n",
        "car_train_df.columns = car_train_df.columns.str.strip()\n",
        "car_test_df.columns = car_test_df.columns.str.strip()\n",
        "\n",
        "# Align the columns of the test dataset with the training dataset\n",
        "car_test_df = car_test_df.reindex(columns=car_train_df.columns, fill_value='missing')\n",
        "\n",
        "# Prepare data\n",
        "car_X_train = car_train_df.drop('acc', axis=1)\n",
        "car_y_train = car_train_df['acc']\n",
        "car_X_test = car_test_df.drop('acc', axis=1)\n",
        "car_y_test = car_test_df['acc']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo5Iwq7WSa3W",
        "outputId": "b4a9bf19-677c-41e0-9dbc-6bd2da838dc3"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Columns: Index(['low', 'vhigh', '4', '4.1', 'big', 'med', 'acc'], dtype='object')\n",
            "Test Data Columns: Index(['vhigh', 'high', '5more', '2', 'small', 'low', 'unacc'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify columns in training set but not in test set\n",
        "missing_cols = [col for col in car_X_train.columns if col not in car_X_test.columns]\n",
        "print(\"Missing Columns in Test Set:\", missing_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6X1km0AW8re",
        "outputId": "1fc8684a-5bec-4a05-c686-e44b37109271"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Columns in Test Set: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etwN6UAtXCTS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}